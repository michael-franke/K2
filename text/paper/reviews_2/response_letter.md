# Response to editor and reviewer comments

The main changes from the previous version are:

1. careful reformulation of conclusions to be drawn from our data in line with reviewer 2's suggestions; concretely:
	a. we stress (even more than before) that grammaticalism qua "core theory" is compatible with our data, while traditionalism is not; 
	b. still, we maintain that grammaticalism qua "core theory" is *trivially* compatible with our data, because it would not be inconsistent with any possible outcome of our experiment; 
	c. the only auxiliary assumption for grammaticalism that is directly applicable to our experiment (selecting reading preferences in terms of logical strength alone) is not compatible with our data.
2. shortening of section 3 to remove unnecessary detail in predictions of "core theories"
3. addition of a few elements of emphasis in introduction, Section 4 and reflection section 6, in response to reviewer 2's comments, which made clear that the previous version may not have made the motivation of our design sufficiently clear


## Editor comments

> I would like to ask two things of you: 
>
> (1) have a good think about the balanced conclusion you draw (the data are hard for both sides of the theoretical divide --- reviewer 2: the data clearly favours grammaticalism) and address the reviewer's worry as good as you can (s/he can't be the only one interpreting your paper like that); 

We agree that our previous version has not been ideally clear on this. It is not our intention to polarize by misleading rhetorics. We have tried to make very clear in the current version that our main conclusions from our data are (as already stated above):

a. we stress (even more than before) that grammaticalism qua "core theory" is compatible with our data, while traditionalism is not; 
b. still, we maintain that grammaticalism qua "core theory" is *trivially* compatible with our data, because it would not be inconsistent with any possible outcome of our experiment; 
c. the only auxiliary assumption for grammaticalism that is directly applicable to our experiment (selecting reading preferences in terms of logical strength alone) is not compatible with our data.


> (2) rethink the value of the fine-grained description of the landscape of theoretical options (section 3.1/3.2).

Although we had thought that it would be good for the readers to see the full space of possible predictions about preference patterns that relevant "core theories" + "auxiliary hypotheses" give, we agree that it is not strictly necessary to introduce all of these distinctions. We have therefore removed those chunks of Section 3 which are not strictly relevant for late discussions (including Table 2, which summarized the predictions). Some particular "auxiliary assumptions" are taken up in the discussion section 6, but only those that are relevant for the overall discussion, like Magri's appeal to obligatory exhaustification, which is an example for how grammaticalism could predict our data.

## Reviewer 1

Reviewer 1 had only minor remarks.

> Perhaps I am persistently misreading something, but on page 4, should it say that the dots on the right of each diagram (of Figure 1) are papers, and the dots on the left represent students?

Yes, this is right: our oversight. We added this to the Figure caption for clarity.

> It would help, in describing Figure 3, to mention that the sentences about them referred to letters and circles. 

This was added to the text.


> Page 20, the Clifton et al. 2002 reference isn't really very relevant to the point being made. If the authors want to cite counterevidence, they would do better with Gilboy, E., Sopena, J., Clifton, C. Jr., & Frazier, L. (1995). Argument structure and association preferences in Spanish and English Compound NPs. Cognition, 54(131-167). But it's not necessary. The citation of Konieczny and  Hemforth says what needs to be said.

PETRA?! -> take out reference to Clifton et al?


> Page 41, bottom, the references to Figure 16c doesn't seem to be correct. 

Corrected!

## Reviewer 2

Reviewer 2 actually raises many points, not all of which are fully clear to us. We tried our very best to address all of the issues raised (insofar as we understood what was asked of us), but paid particular attention to those issues flagged as most important by the reviewer herself/himself or the editor.

[In the following, we reproduce the full review and use boldface to indicate the aspects that subsequent comments target.]

>The authors have done a good job responding to the first round of feedback. As in the previous round of review, I believe the paper makes a valuable contribution to the literature on scalar strengthening, and that the paper should be published. However, I continue to believe there is room for improvement. Specifically, **I believe the paper can be streamlined by taking fuller advantage of previous results**, which I hope will also clarify the contributions that the paper makes. 
>
>My most important comment, which I'll try to spell out in Section 1 below, is that the question-answer structure of the paper does not come across as cleanly as it should. **To my mind, the paper aims to answer two questions: (i) Are embedded strengthenings licensed only under marked prosody, i.e., is the Prosodic Marking Hypothesis true? (ii) Are there preferences for the different readings predicted by theories of strengthening? If so, what are they, and how are they determined?** 
>
> I believe the paper answers (i) quite nicely, but it burdens the reader with too much irrelevant information in setting up and addressing the question (much of section 3 of the paper up to but not including section 3.3 on the Prosodic Marking Hypothesis). Concerning question (ii), the paper leaves it unresolved, which would be fine had the authors not mischaracterized the question by invoking the Strongest Meaning Hypothesis in the way that they did (as I hope to clarify below). If these issues could be resolved in a revised version, I would have no serious objection to publication.

We feel that this description of what the paper is about is unfortunately not entirely correct. This could lead to certain misunderstandings, so we clarify our position here. We have also added to the text (introduction, especially the relevant Section 4.4, section 6) to strengthen our view of and motivation for what we are doing. (It is our fault, of course, that this has not been sufficiently clear in the previous version.)

One of our main goals in this paper is, indeed, to address the effects of prosody, but with a particular motivation, namely to rule out effects of "silent prosody" as confounds in the interpretation of earlier data. This is important because all previous experimental results that depend on visual presentation of sentences could, in principle, be subject to doubt if we hypothesize (like many do) that prosody plays a role in this domain. This also includes the results of Chemla & Spector. This is why we want to be more careful in this paper and not take for granted the conclusions of Chemla & Spector contrary to what the reviewer suggests we should do.

Our reluctance to accept Chemla & Spector's conclusions also comes from the recent critique of, in particular, Bart Geurts and Bob van Tiel, who argue that Chemla & Spector's results could be influenced unduly by pictorial effects. This is the main motivation for our incremental verification task, as argued in Section 4.4 and followed up in the reflection section 6.

In effect, the main point of our paradigm is that we would not want to take "full advantage of previous results" but (given the published criticism of these) take a careful reassessment and a novel experimental approach. We hope that by adding few strategically placed elements of emphasis and explanation (introduction, sections 4 & 6) this will become more transparent.

<!---Unfortunately, we do not understand in what sense the paper leaves question (ii) unresolved, according to the reviewer. To be clear on this, we wanted to get experimental evidence for preferences among putative readings, and we did. We also discuss whether these are predicted by the competing theories. We have adjusted the formulation of these conclusions according to the reviewer's well-taken suggestions in the new version (see below). We never meant to address the question how preferences are determined (and are not clear on what this should mean).-->


>
>
>Section 1: The question-answer structure of the paper
>
>It will help me to discuss the paper's contributions by taking Chemla & Spector (2011, hf. CS) as relevant background, as they also aimed to detect embedded readings in AS and ES sentences and found results that are sometimes supported but sometimes challenged by the present authors. I focus here on ES sentences, in part because AS sentences are not ideal for teasing apart "grammaticalism" from "unrestricted traditionalism", for reasons discussed in CS and elsewhere. My aim here is to identify some of the important empirical results from the current paper, and to relate them to questions (i) and (ii) above:
>
>Empirical Result (1): Like CS, but using a different method, the present authors find that embedded strengthenings are available.
>
>Consequences of (1): This result supports two of CS's claims. First, it provides further evidence for embedded strengthening (and hence, on the face of it, against Traditionalism -- pending further clarification of "typicality"), though of course it leaves open the question in (i) above. Second, **(1) provides further support for CS's claim that the Strongest Meaning Hypothesis is probably *not* the right disambiguation principle (see note 6 of CS, and CS's section 5.5.2)**. 

We are very grateful for drawing our attention to the fact that we should mention that Chemla & Spector have already discussed their data as countering the Strongest Meaning Hypothesis. Our position to this is that, yes, we provide further evidence, but also further evidence that is relevant, given the doubts that were brought forth against Chemla & Spector's design and interpretation and the additional doubts that arise from issues with "silent prosody".

<!--There must be some misunderstanding here (see also above): the incremental verification task is motivated by worries about potential pictorial effects. This is orthogonal to the issue of "silent prosody".-->


> Empirical Result (2): The present authors find that embedded strengthenings are available independent of prosodic marking. This result is totally new, and is made possible by their new method (their Incremental Verification Task).
>
> Consequences of (2): This result argues against the Prosodic Marking Hypothesis (cf. question (i) above).
> 
> (3) Empirical Result (3): The present authors find that the literal reading is preferred to the local reading, which is in stark opposition with what CS found. 
>
>Consequences of (3): Given the discussion in (1) above, an obvious challenge is to explain what might have led to different preferences in CS's sample and the one in the present paper (cf. question (ii) above).
>
> If my reading of the paper is correct, then several changes to the paper are in order. 
>
>   - First, I believe **much of the discussion in section 3 concerning auxiliary assumptions should be shortened or even deleted entirely.** To begin with, much of the discussion about Traditionalism seems irrelevant to me. The really important assumption here is the Prosodic Marking Hypothesis, which can be simply stated without bothering with the distinction between weak/strong and restricted/unrestricted traditionalism. In fact, so far as I can tell, nothing that the authors say later in the paper bears on these differences, in part because traditionalism qua core theory is inconsistent with the authors' results. Turning to grammaticalism, in light of the fact that **the Strongest Meaning Hypothesis was already argued in CS to be inoperative (or at least, not dominant) in ES sentences, the authors' decision to take that as the most promising example of a disambiguation criterion seems unjustified.** In sum, the authors introduce many discourse referents in section 3 corresponding to possible combinations of core theory + auxiliary assumptions (all the variants of traditionalism and the conjunction of grammaticalism and the SMH), and at the end of the paper we are reminded that CS already gave us reason to reject them all. This is not very cooperative.   
>   **My concrete suggestion is to considerably shorten Section 3 by not getting into all the choice points concerning Traditionalism (weak/strong, restricted/unrestricted) or Grammaticalism (Magri/QUD/SMH). All of these are irrelevant to the Prosodic Marking Hypothesis, and in any event nothing new is discovered by paper's end about the right auxiliary assumptions**, other than that the answer is unlikely to be straightforward (cf. the conflict with CS's results alluded to above).

We have taken up the suggestion to shorten Section 3 in the way that the reviewer describes.

On the other hand, for the very reasons described above, we are reluctant to accept the results and conclusions of Chemla & Spector as given. Since our design was motivated by catering to the very problems raised for Chemla & Spector, we do believe that our data gives new and interesting information about preference of readings. This is also because, as we argue in Section 4.4, we explicitly compare data from embedded scalars with other ambiguous constructions in the very same experiment (same method, same subject pool).

> - Second, the authors' abstract and the discussion in the paper make it clear that there are challenges for both traditionalism and grammaticalism. This is very important, but **the authors' discussion makes it seem as though the challenges for the two approaches are more on a par than they actually are. Traditionalism (as a core theory) is inconsistent with the authors' data, and grammaticalism (as a core theory) is consistent with their data**. Of course, grammaticalism is still in need of auxiliary assumptions to account for the data about preferences, but this should occasion no surprise. For example, last I checked the psycholinguistics community was still trying to figure out, say, how PP-attachment ambiguities are resolved; just because we don't know how, this does not lead anyone to suggest that syntactic theories that generate PP-attachment ambiguities are in need of "refinement", does it?    
>   My concrete suggestion is to **rephrase the abstract and other relevant passages in the paper so that it does not misleadingly suggest that grammaticalism qua core theory faces any particular difficulty with the authors' results**; what is missing here is a theory of preference, but this is needed for any theoretical approach to strengthening. For note that the discrepancy between CS's findings and the present authors' findings concerning preferences need to be accounted for one way or another; since this is a problem for everyone, I don't think it is fair to single out grammaticalism as being in need of refinement, at least not until it is shown that some other approach predicts the discrepancy between CS and the present authors' data on preferences.

We agree that our previous version did not make this clear enough. We reformulated relevant locations to make clear what our position is, namely (same as above):

	a. we stress (even more than before) that grammaticalism qua "core theory" is compatible with our data, while traditionalism is not; 
	b. still, we maintain that grammaticalism qua "core theory" is *trivially* compatible with our data, because it would not be inconsistent with any possible outcome of our experiment; 
	c. the only auxiliary assumption for grammaticalism that is directly applicable to our experiment (selecting reading preferences in terms of logical strength alone) is not compatible with our data.

> Section 2: Minor comments/thoughts (feel free to ignore)
>
> A: "Exactly one" as monotonic: **The authors suggest, based on the "true" responses at Step 2, that some of their participants might have re-interpreted "exactly one" as "at least one." I'm wondering if there is a less radical way to make sense of their participants' behaviour: for what it's worth, my intuition is that there might be domain-restriction effects here.** There is exactly one uncovered bell at Step 2; thus, the sentence is literally true under a reading in which the domain of the quantifier is restricted to this one individual. I'm not exactly sure how to dissociate this suggestion from the authors', and I of course wouldn't insist that the authors do this. I raise the idea here simply for their consideration. With this in mind, in future work perhaps the authors might consider examining what would happen if Step 1 were followed instead by what is currently Step 3. The domain-restriction proposal would predict less "true" responses here because now there are two bells that are salient in the domain, but an "at least one" reading would still easily permit a "true" response here. (Note that getting rid of the current Step 2 is largely harmless, since global readings were basically absent in this paradigm.)

This is a good and interesting suggestion. We cannot follow up on this in the paper, but acknowledge the point in a footnote.

> B: The Strongest Meaning Hypothesis, Again: **As I noted earlier, it does not seem appropriate to assume the SMH for this paradigm in light of CS's results and discussion.** However, I should like to add that one has to be careful about what the SMH actually states when we consider exhaustification, and here perhaps CS themselves could have been more careful. When we compare the strength of various sentences that differ in the placement of EXH, we have to be careful about what the alternatives to EXH are. So far as I can tell, the SMH may well still be in the running as a disambiguation criterion, if only we could be sure what the alternatives are in any given experimental setup. Since we don't know this, we can't really be sure whether the SMH has been properly tested. 

As mentioned above, we are grateful for reminding us to take into consideration Chemla & Spector's discussion of the SMH in this case. Their footnote 6 makes a similar point to the reviewer's. We acknowledge that Chemla & Spector believe that logical strength may still play a role despite their findings and that this may also extend to our findings in the reflection section 6. However, like Chemla & Spector and the reviewer, we have no strong vision of how this idea could be realized and so must leave it for future work.

> Having said this, **it's still not clear to me that there is any motivation to appeal to the SMH the way the authors do.** Putting aside the issues raised earlier, it is important to note that **the works that the authors cite were all very careful to limit the immediate applicability of the SMH to either reciprocals (Dalrymple et al.) or to plural predication more generally (Winter). One is of course welcome to try extending its applicability, but my reading of the literature is that the SMH was not intended as a general disambiguation principle** (lest it run into well-known issues in other areas, e.g., preferences in scope-ambiguities).

It seems that we have reach rock bottom here, where the reviewer's view differs irresolvably from ours. We consider Chierchia, Fox and Spector (2012) "The Grammatical View of Scalar Implicatures and the Relationship between Semantics and Pragmatics" a great and inspiring paper by great and inspiring minds. This paper suggests to use the SMH for disambiguating parses. Taking great and inspiring papers and minds seriously, we therefore do not think that it is whimsical to pay attention to the SMH, especially, as we stress, our emphasis on it is because it is the only fully spelled out proposal for enriching grammaticalism that applies to our abstract experimental setting.

> C: "Ex ante" predictions: **The authors in many places write that certain proposals are not formulated as "ex ante" predictions. But the predictions of all the theories the authors discuss are all fully predictive: given a sentence and a context, just about every theory of strengthening I know clearly predicts how a scalar sentence will be interpreted.** Of course, in experimental settings many relevant features of the context are left open, and hence participants have to guess what context they're in (see e.g., Crain & Steedman, 1985). This is certainly the case for the author's experiment, in which many of the contextual features that are important for strengthening are unspecified (e.g., relevance, assumptions about the speaker's mental state, etc). But this is a general feature of psycholinguistic studies, is it not? If you leave open crucial contextual features, participants have to guess those values. Does this make the theories any less predictive? Is the difficulty in pinning down a context a difficulty for the theory or for the experimenter?

We are grateful for this comment, because it shows that we have been insufficiently clear on our intended meaning of *ex ante* predictions. We have clarified this in footnote XXX. We are interested in *ex ante* predictions FOR OUR EXPERIMENT, not general predictions *given a set of contextual parameters*.